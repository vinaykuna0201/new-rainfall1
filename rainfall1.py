# -*- coding: utf-8 -*-
"""rainfall1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B_AA36vVr-ACr634cOzsm_WUPI8xfuV1

Importing Libraries and Dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import RandomOverSampler
from sklearn.metrics import classification_report,confusion_matrix

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('Rainfall.csv')
df.head()

df.shape

df.info()

df.describe().T

"""Data Cleaning"""

df.isnull().sum()

df.columns

df.rename(str.strip,
		axis='columns',
		inplace=True)

df.columns

for col in df.columns:

    # Checking if the column contains
    # any null values
    if df[col].isnull().sum() > 0:
        val = df[col].mean()
        df[col] = df[col].fillna(val)

df.isnull().sum().sum()

"""Exploratory Data Analysis"""

plt.pie(df['rainfall'].value_counts().values,
		labels = df['rainfall'].value_counts().index,
		autopct='%1.1f%%')
plt.show()

df.groupby('rainfall').mean()

features = list(df.select_dtypes(include = np.number).columns)
features.remove('day')
print(features)

plt.subplots(figsize=(15,8))

for i, col in enumerate(features):
    plt.subplot(3,4, i + 1)
    sb.distplot(df[col])
plt.tight_layout()
plt.show()

plt.subplots(figsize=(15,8))

for i, col in enumerate(features):
  plt.subplot(3,4, i + 1)
  sb.boxplot(df[col])
plt.tight_layout()
plt.show()

df.replace({'yes':1, 'no':0}, inplace=True)

plt.figure(figsize=(10,10))
sb.heatmap(df.corr() > 0.8,
		annot=True,
		cbar=False)
plt.show()

df.drop(['maxtemp', 'mintemp'], axis=1, inplace=True)

"""Model Training,Model Evaluation"""

features = df.drop(['day', 'rainfall'], axis=1)
target = df.rainfall

X_train, X_test, \
	Y_train, Y_test = train_test_split(features,
									target,
									test_size=0.2,
									stratify=target,
									random_state=2)

# As the data was highly imbalanced we will
# balance it by adding repetitive rows of minority class.

model = LogisticRegression()
model.fit(X_train,Y_train)

predict = model.predict(X_test)

metrics.roc_auc_score(predict,Y_test)

classification_report(predict,Y_test)

from sklearn.metrics import classification_report

# Example true labels and predictions
Y_test = [0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]  # True labels
predict = [0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1]  # Predicted labels

# Generate classification report
report = classification_report(Y_test, predict, target_names=['0', '1'])

# Print the report
print(report)

models = [LogisticRegression(), XGBClassifier(), SVC(kernel='rbf', probability=True)]

for i in range(3):
  models[i].fit(X, Y)

  print(f'{models[i]} : ')

  train_preds = models[i].predict_proba(X)
  print('Training Accuracy : ', metrics.roc_auc_score(Y, train_preds[:,1]))

  val_preds = models[i].predict_proba(X_val)
  print('Validation Accuracy : ', metrics.roc_auc_score(Y_val, val_preds[:,1]))
  print()

confusion_matrix(predict,Y_test)

import pickle

pickle.dump(model,open('proj.pkl','wb'))

df.columns

